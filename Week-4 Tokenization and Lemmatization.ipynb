{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1ba43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2028582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/69937/pg69937.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc00ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5961b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7597043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e5ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'Shakespeare', \"'s\", 'Roman', 'Plays', 'and', 'Their', 'Background', ',', 'by', 'Mungo', 'William', 'MacCallum', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018f4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "# Preprocessing - RE to clean any html tags or unnecessary char sequences\n",
    "# Pos Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0233a954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "porter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b059d001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "porter = LancasterStemmer()\n",
    "porter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c5d91be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "porter = RegexpStemmer('ing$')\n",
    "porter.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4c84e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "porter = SnowballStemmer('english')\n",
    "porter.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d56962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'Shakespeare', \"'s\", 'Roman', 'Plays', 'and', 'Their', 'Background', ',', 'by', 'Mungo', 'William', 'MacCallum', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before']\n",
      "\n",
      "\n",
      "['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'of', 'shakespear', \"'s\", 'roman', 'play', 'and', 'their', 'background', ',', 'by', 'mungo', 'william', 'maccallum', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyon', 'anywher', 'in', 'the', 'unit', 'state', 'and', 'most', 'other', 'part', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrict', 'whatsoev', '.', 'you', 'may', 'copi', 'it', ',', 'give', 'it', 'away', 'or', 're-us', 'it', 'under', 'the', 'term', 'of', 'the', 'project', 'gutenberg', 'licens', 'includ', 'with', 'this', 'ebook', 'or', 'onlin', 'at', 'www.gutenberg.org', '.', 'if', 'you', 'are', 'not', 'locat', 'in', 'the', 'unit', 'state', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'law', 'of', 'the', 'countri', 'where', 'you', 'are', 'locat', 'befor']\n"
     ]
    }
   ],
   "source": [
    "p = \"\"\n",
    "text = p.split()\n",
    "l = []\n",
    "for i in text:\n",
    "    t = SnowballStemmer('english')\n",
    "    l.append(t.stem(i))\n",
    "print(text)\n",
    "print('\\n')\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ceb5630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'stem', 'algorithm', 'is', 'an', 'older', 'one.', 'it’', 'from', 'the', '1980', 'and', 'it', 'main', 'concern', 'is', 'remov', 'the', 'common', 'end', 'to', 'word', 'so', 'that', 'they', 'can', 'be', 'resolv', 'to', 'a', 'common', 'form.', 'it’', 'not', 'too', 'complex', 'and', 'develop', 'on', 'it', 'is', 'frozen.', 'typically,', 'it’', 'a', 'nice', 'start', 'basic', 'stemmer,', 'but']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "text = \"This stemming algorithm is an older one. It’s from the 1980s and its main concern is removing the common endings to words so that they can be resolved to a common form. It’s not too complex and development on it is frozen. Typically, it’s a nice starting basic stemmer, but it’s not really advised to use it for any production/complex application. Instead, it has its place in research as a nice, basic stemming algorithm that can guarantee reproducibility. It also is a very gentle stemming algorithm when compared to others.\"\n",
    "stemmed = [porter.stem(token) for token in text.split()]\n",
    "print(stemmed[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b698d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhamo\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac0e6d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize('better', pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf40f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
